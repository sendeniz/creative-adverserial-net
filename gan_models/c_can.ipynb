{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"c_can.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"cubgfGvaRCCY"},"source":["### Wikiart: Conditional Generative Adverserial Network (cCAN)"]},{"cell_type":"markdown","metadata":{"id":"_TzAj5u2RNzS"},"source":["### Load Libraries"]},{"cell_type":"code","metadata":{"id":"3Edbc9vQkpe5","executionInfo":{"status":"ok","timestamp":1623858473694,"user_tz":-120,"elapsed":4451,"user":{"displayName":"Arian Askari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiIw8AJ_FyYd3Z5pNgWvAnfn3agwPoJEASc1wWK3w=s64","userId":"06715765459286968049"}}},"source":["import torchvision\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms\n","from torch.utils import data\n","from torch.utils.data import DataLoader\n","from google.colab import drive\n","import argparse\n","import os\n","from os import walk\n","import random\n","import torch\n","import torch.nn as nn\n","import torch.nn.parallel\n","import torch.backends.cudnn as cudnn\n","import torch.optim as optim\n","import torch.utils.data\n","import torchvision.transforms as transforms\n","import torchvision.utils as vutils\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.animation as animation\n","from IPython.display import HTML\n","import time\n","import sys\n","import tensorflow as tf\n","from torch.autograd import Variable"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eqV99DBZ3T21"},"source":["\n","### Mount Google Drive"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":553},"id":"Tiq__tJj3YAl","executionInfo":{"status":"error","timestamp":1623858494121,"user_tz":-120,"elapsed":20442,"user":{"displayName":"Arian Askari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiIw8AJ_FyYd3Z5pNgWvAnfn3agwPoJEASc1wWK3w=s64","userId":"06715765459286968049"}},"outputId":"01cdb810-ec5e-4c1a-bd61-5de2ca1f5a48"},"source":["# mount drive\n","drive.mount('/content/drive')\n","!wget dropboxlink"],"execution_count":2,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \"\"\"\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-184b6f877de3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# mount drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    258\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dfs-auth-dance'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfifo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfifo_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m           \u001b[0mfifo_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_prompt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m       \u001b[0mwrote_to_fifo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"TcxZKFdf3ZIu"},"source":["### Load Metric Modules"]},{"cell_type":"code","metadata":{"id":"hz2tKDcS3cwD","executionInfo":{"status":"aborted","timestamp":1623858494048,"user_tz":-120,"elapsed":125,"user":{"displayName":"Arian Askari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiIw8AJ_FyYd3Z5pNgWvAnfn3agwPoJEASc1wWK3w=s64","userId":"06715765459286968049"}}},"source":["# load inception score metric\n","inception_path = '/content/drive/MyDrive/neural_networks/modules/inception_score_pytorch'\n","#!cat '/content/drive/MyDrive/neural_networks/modules/inception_score_pytorch/inception_score.py'\n","sys.path.append(inception_path)\n","from inception_score import inception_score\n","frechet_path = '/content/drive/MyDrive/neural_networks/modules/frechet_inception_distance'\n","#!cat '/content/drive/MyDrive/neural_networks/modules/frechet_inception_distance/frechet_inception_distance.py'\n","sys.path.append(frechet_path)\n","from frechet_inception_distance import frechet_id"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W1iHEXw0F3Kf"},"source":["### Training Parameters"]},{"cell_type":"code","metadata":{"id":"KEysP4YdFyMA","executionInfo":{"status":"aborted","timestamp":1623858494056,"user_tz":-120,"elapsed":119,"user":{"displayName":"Arian Askari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiIw8AJ_FyYd3Z5pNgWvAnfn3agwPoJEASc1wWK3w=s64","userId":"06715765459286968049"}}},"source":["num_epochs = 150\n","batch_size = 64\n","learning_rate = 1e-4\n","use_gpu = True\n","ngpu = 1\n","img_size = 64\n","# device = torch.device(\"cuda:0\" if use_gpu and torch.cuda.is_available() else \"cpu\")\n","device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n","tolerance = 1e-6\n","# use smaller wiki art data for testing\n","use_test_data = True\n","n_workers = 8"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"omOB2r-uZsqr"},"source":["### Load Subset Wikiart Data"]},{"cell_type":"code","metadata":{"id":"t8Z5dsltP9dK","executionInfo":{"status":"aborted","timestamp":1623858494058,"user_tz":-120,"elapsed":119,"user":{"displayName":"Arian Askari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiIw8AJ_FyYd3Z5pNgWvAnfn3agwPoJEASc1wWK3w=s64","userId":"06715765459286968049"}}},"source":["# print subfolders/art styles of the wikiart subset directory\n","#!ls '/content/drive/MyDrive/neural_networks/data/wikiart_resized'\n","# set parent folder of wikiart as file directory\n","if use_test_data == True:\n","    data_dir = '/content/drive/MyDrive/neural_networks/data/wikiart_subset'\n","\n","elif use_test_data == False:\n","    data_dir = '/content/drive/MyDrive/neural_networks/data/wikiart_resized'\n","\n","# set random seed\n","random.seed(1486438)\n","torch.manual_seed(1486438)\n","\n","# define transformer for data loader\n","# resize and normalize data for slight performance boost\n","img_transform = transforms.Compose([\n","                                    transforms.Resize((img_size, img_size)),\n","                                    transforms.ToTensor(),\n","                                    transforms.Normalize((0.5, 0.5, 0.5), \n","                                                         (0.5, 0.5, 0.5))\n","                                  ])\n","\n","dataset = datasets.ImageFolder(root=data_dir,\n","                           transform=img_transform)\n","# Create the dataloader\n","dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n","                                         shuffle=True, num_workers = n_workers)\n","\n","# Plot some training images\n","real_batch = next(iter(dataloader))\n","plt.figure(figsize=(8,8))\n","plt.axis(\"off\")\n","plt.title(\"Training Images\")\n","plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device), padding=2, \n","                                         normalize=True).cpu(),(1,2,0)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gsrsL9BMSqj3"},"source":["### Custom Weight Initialization"]},{"cell_type":"code","metadata":{"id":"RiYOwlKGbm2B","executionInfo":{"status":"aborted","timestamp":1623858494063,"user_tz":-120,"elapsed":122,"user":{"displayName":"Arian Askari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiIw8AJ_FyYd3Z5pNgWvAnfn3agwPoJEASc1wWK3w=s64","userId":"06715765459286968049"}}},"source":["# custom weights initialization called on netG and netD\n","# set random seed\n","random.seed(1486438)\n","torch.manual_seed(1486438)\n","def weights_init(m):\n","    classname = m.__class__.__name__\n","    if classname.find('Conv') != -1:\n","        nn.init.normal_(m.weight.data, 0.0, 0.02)\n","    elif classname.find('BatchNorm') != -1:\n","        nn.init.normal_(m.weight.data, 1.0, 0.02)\n","        nn.init.constant_(m.bias.data, 0)\n","\n","def gaussian(ins, mean, stddev):\n","    noise = Variable(ins.data.new(ins.size()).normal_(mean, stddev))\n","    return ins + noise"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4jNHzBVh3B-w"},"source":["### Gan Parameters"]},{"cell_type":"code","metadata":{"id":"b0IM0Px3HpvV","executionInfo":{"status":"aborted","timestamp":1623858494070,"user_tz":-120,"elapsed":127,"user":{"displayName":"Arian Askari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiIw8AJ_FyYd3Z5pNgWvAnfn3agwPoJEASc1wWK3w=s64","userId":"06715765459286968049"}}},"source":["# number of channels (1 = gray, 3 = RGB colors)\n","nc = 3\n","# number/size of latent vector z for the generator input\n","nz = 150\n","# size/number of feature maps in generator\n","ngf = 64\n","# size/number of feature maps in discriminator\n","# ndf = 64\n","ndf = 32\n","\n","# number of art style classes\n","if use_test_data == True:\n","  # test wikiart has 5 art style\n","  n_class = 5\n","elif use_test_data == False:\n","  # complete data has 27 art styles\n","  n_class = 27\n","\n","# number of examples to be generated\n","example_size = 8\n","\n","# define fixed noise to sample images from the latent space of the generator\n","fixed_noise = torch.randn(n_class*example_size, nz, 1, 1, device=device)\n","\n","fixed_label = torch.tensor(list(np.repeat([i for i in range(n_class)], \n","                                          example_size))).type(torch.LongTensor).to(device)\n","\n","# establish convention for real and fake labels \n","real_label = 1.\n","fake_label = 0."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"npWIGfwlFflF","executionInfo":{"status":"aborted","timestamp":1623858494073,"user_tz":-120,"elapsed":121,"user":{"displayName":"Arian Askari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiIw8AJ_FyYd3Z5pNgWvAnfn3agwPoJEASc1wWK3w=s64","userId":"06715765459286968049"}}},"source":["class Generator(nn.Module):\n","    def __init__(self, ngpu=1):\n","        super(Generator, self).__init__()\n","        self.label_emb = nn.Embedding(n_class, n_class)\n","        self.ngpu = ngpu\n","        self.main = nn.Sequential(\n","            # input is Z, going into a convolution\n","            nn.ConvTranspose2d( nz + n_class, ngf * 8, 4, 1, 0, bias=False),\n","            nn.BatchNorm2d(ngf * 8),\n","            nn.ReLU(True),\n","            # state size. (ngf*8) x 4 x 4\n","            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ngf * 4),\n","            nn.ReLU(True),\n","            # state size. (ngf*4) x 8 x 8\n","            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ngf * 2),\n","            nn.ReLU(True),\n","            # state size. (ngf*2) x 16 x 16\n","            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ngf),\n","            nn.ReLU(True),\n","            # state size. (ngf) x 32 x 32\n","            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n","            nn.Tanh()\n","            # state size. (nc) x 64 x 64\n","        )\n","    def forward(self, noise_input, labels):\n","        # Concatenate label embedding and image to produce input\n","        #print(self.label_emb(labels).unsqueeze(2).unsqueeze(3).shape, noise_input.shape, labels.shape)\n","        gen_input = torch.cat((self.label_emb(labels).unsqueeze(2).unsqueeze(3), noise_input), 1)\n","        img = self.main(gen_input)\n","        img = img.view(img.size(0), *(nc, img_size, img_size))\n","        return img\n","\n","# Discriminator Model\n","class Discriminator(nn.Module):\n","    def __init__(self, ngpu=1):\n","        super(Discriminator, self).__init__()\n","        self.label_emb = nn.Embedding(n_class, ndf*16*4)\n","        self.ngpu = ngpu\n","        self.main = nn.Sequential(\n","            # input is (nc) x 64 x 64\n","            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # state size. (ndf) x 32 x 32\n","            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ndf * 2),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # state size. (ndf*2) x 16 x 16\n","            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ndf * 4),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # state size. (ndf*4) x 8 x 8\n","            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ndf * 8),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # state size. (ndf*8) x 4 x 4\n","            nn.Conv2d(ndf * 8, ndf * 16, 4, 2, 1, bias=False), \n","            nn.BatchNorm2d(ndf * 16),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # state size. (ndf*16) x 2 x 2\n","            nn.Flatten()\n","        )\n","        self.linear = nn.Sequential(\n","        nn.Linear(ndf*16*4*2, ndf*16),    \n","        nn.LeakyReLU(0.2, inplace=True),   \n","        nn.Linear(ndf*16, 1),\n","        nn.Sigmoid()    \n","        )\n","\n","        self.discriminate = nn.Sequential(\n","            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n","            nn.Sigmoid()\n","            )\n","        \n","        self.classify = nn.Sequential(\n","            nn.Conv2d(ndf * 8, n_class, 4, 1, 0, bias=False)\n","        )\n","\n","    def forward(self, input, labels):\n","        # changes assignment to x : disc_out = self.main(input) \n","        x = self.main(input)\n","        d_out = self.discriminate(x)\n","        c_out = self.classify(x)\n","        \n","        # changes assignment to x: linear_input = torch.cat((self.label_emb(labels), disc_out), 1)\n","        linear_input = torch.cat((self.label_emb(labels), x), 1)\n","        linear_output = self.linear(linear_input.squeeze())\n","        #print(input.shape, labels.shape, disc_out.shape, linear_input.shape, linear_output.shape)\n","        #print(input.shape, labels.shape, x.shape, linear_input.shape, linear_output.shape)\n","\n","        return linear_output.unsqueeze(2).unsqueeze(3), d_out, c_out\n","    \n","generator = Generator()\n","discriminator = Discriminator()\n","\n","# apply the weights_init function to randomly initialize all weights\n","# to mean=0, stdev=0.02\n","generator.apply(weights_init)\n","discriminator.apply(weights_init)\n","\n","# device = torch.device(\"cuda:0\" if use_gpu and torch.cuda.is_available() else \"cpu\")\n","device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n","generator = generator.to(device)\n","discriminator = discriminator.to(device)\n","\n","num_params_gen = sum(p.numel() for p in generator.parameters() if p.requires_grad)\n","num_params_disc = sum(p.numel() for p in discriminator.parameters() if p.requires_grad)\n","print('Number of parameters for generator: %d and discriminator: %d' % (num_params_gen, num_params_disc))\n","print('Generator Architecture:', generator)\n","print('Discriminator Architecture:', discriminator)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eFnIaW8wJR1w"},"source":["### Define Storage Location"]},{"cell_type":"code","metadata":{"id":"EuZ24G2xJQWx","executionInfo":{"status":"aborted","timestamp":1623858494075,"user_tz":-120,"elapsed":114,"user":{"displayName":"Arian Askari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiIw8AJ_FyYd3Z5pNgWvAnfn3agwPoJEASc1wWK3w=s64","userId":"06715765459286968049"}}},"source":["# mount google drive for saving checkpoints\n","drive.mount('/content/drive')\n","\n","# checkpoint generator file name\n","gen_save_name = 'wikiart_c_gen.cpt'\n","# define location to store checkpoints for generator\n","path_gen = F'/content/drive/MyDrive/neural_networks/checkpoints/{gen_save_name}'\n","\n","# checkpoint discriminator file name\n","disc_save_name = 'wikiart_c_disc.cpt'\n","# define location to store checkpoints for discriminator\n","path_disc = F'/content/drive/MyDrive/neural_networks/checkpoints/{disc_save_name}'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_1T8K2sKJs_q"},"source":["### Train GAN"]},{"cell_type":"code","metadata":{"id":"diEJfdGAJpyA","executionInfo":{"status":"aborted","timestamp":1623858494079,"user_tz":-120,"elapsed":112,"user":{"displayName":"Arian Askari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiIw8AJ_FyYd3Z5pNgWvAnfn3agwPoJEASc1wWK3w=s64","userId":"06715765459286968049"}}},"source":["gen_optimizer = torch.optim.Adam(params=generator.parameters(), lr=learning_rate,\n","                                 betas=(0.5, 0.999))\n","disc_optimizer = torch.optim.Adam(params=discriminator.parameters(), lr=learning_rate,\n","                                  betas=(0.5, 0.999))\n","\n","\n","# loss per iteration\n","gen_iter_loss = []\n","disc_iter_loss = []\n","#loss per epoch\n","gen_loss_avg = []\n","disc_loss_avg = []\n","\n","entropies = []\n","\n","gen_loss_avg.append(0)\n","disc_loss_avg.append(0)\n","\n","iters = 0\n","\n","# store generated images \n","img_lst = []\n","# store generated images for gif\n","img_lst_gif = []\n","\n","print(\" Training...\")\n","# For each epoch\n","for epoch in range(num_epochs):\n","\n","    # start couting run time\n","    start_time = time.time() \n","    \n","    gen_loss_avg.append(0)\n","    disc_loss_avg.append(0)\n","    num_batches = 0\n","\n","    # for each batch in the data loader\n","    for i, (data, real_style_labels) in enumerate(dataloader, 0):\n","\n","        # (1) Update discriminator network: maximize log(D(x)) + log(1 - D(G(z)))\n","        # disable gradients to save computation cost\n","        discriminator.zero_grad()\n","        # pass data to local device cpu\n","        real_cpu = data.to(device)\n","        # obtain batch size\n","        b_size = real_cpu.size(0)\n","        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n","        # pass style labels to device\n","        real_style_labels = real_style_labels.to(device)\n","        # fake labels are a random choice of style\n","        fake_style_labels = torch.tensor(np.random.choice(n_class, size = b_size)).type(torch.LongTensor).to(device)\n","\n","        # pass batch to discriminator \n","        # output = discriminator(gaussian(real_cpu, mean=0, stddev=0.5*0.01**(epoch/num_epochs)), real_style_labels).view(-1)\n","        output1, output2, output_style = discriminator(gaussian(real_cpu, mean=0, stddev=0.5*0.01**(epoch/num_epochs)), real_style_labels).view(-1)\n","        \n","        # compute disc loss\n","        # disc_loss_real = F.binary_cross_entropy(output, label)\n","        disc_loss_real = F.binary_cross_entropy(output1, label)\n","        \n","        disc_loss_real_style = F.cross_entropy(output_style.squeeze(), style_label.squeeze())\n","        disc_loss_real  = disc_loss_real + disc_loss_real_style\n","\n","        # Calculate gradients for D in backward pass\n","        disc_loss_real.backward()\n","        D_x = output1.mean().item()\n","\n","        ## Train with all-fake batch\n","        # Generate batch of latent vectors\n","        noise = torch.randn(b_size, nz, 1, 1, device=device)\n","        # Generate fake image batch with G\n","        fake_image_batch = generator(noise, fake_style_labels)\n","        label.fill_(fake_label)\n","        # Classify all fake batch with D\n","        output1 = discriminator(fake_image_batch.detach(), fake_style_labels).view(-1)\n","        # Calculate D's loss on the all-fake batch\n","        disc_loss_fake = F.binary_cross_entropy(output1, label)\n","        # Calculate the gradients for this batch\n","        disc_loss_fake.backward()\n","        D_G_z1 = output1.mean().item()\n","        # Add the gradients from the all-real and all-fake batches\n","        disc_loss = 0.5 * (disc_loss_real + disc_loss_fake)\n","        # Update D\n","        disc_optimizer.step()\n","\n","        # (2) Update generator network: maximize log(D(G(z)))\n","        generator.zero_grad()\n","        label.fill_(real_label)  # fake labels are real for generator cost\n","        # Since we just updated D, perform another forward pass of all-fake batch through D\n","        # output = discriminator(fake_image_batch, fake_style_labels).view(-1)\n","        output1, output2, output_style = discriminator(fake, fake_style_labels).view(-1)\n","\n","        logsoftmax = nn.LogSoftmax(dim=1)\n","        unif = torch.full((data.shape[0], n_class), 1/n_class)\n","        unif = unif.to(device)\n","\n","        # Calculate G's loss based on this output\n","        gen_loss = F.binary_cross_entropy(output1, label)\n","        gen_loss = gen_loss + torch.mean(-torch.sum(unif * logsoftmax(output_style), 1))  \n","        # Calculate gradients for G\n","        gen_loss.backward()\n","        D_G_z2 = output1.mean().item()\n","        # Update G\n","        gen_optimizer.step()\n","\n","\n","        style_entropy = -1 * (nn.functional.softmax(output_style, dim=1) * nn.functional.log_softmax(output_style, dim=1))\n","        style_entropy = style_entropy.sum(dim=1).mean() / torch.log(torch.tensor(n_class).float())\n","\n","\n","        # average loss per iteration to obtain average loss per epoch\n","        gen_loss_avg[-1] += gen_loss.item()\n","        disc_loss_avg[-1] += disc_loss.item()\n","\n","        num_batches += 1\n","\n","        # Output training stats\n","        if i % 40 == 0:\n","            # print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n","            #      % (epoch, num_epochs, i, len(dataloader),\n","            #         disc_loss.item(), gen_loss.item(), D_x, D_G_z1, D_G_z2))\n","            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f\\t Entropy: %.4f' \n","                  % (epoch, num_epochs, i, len(dataloader),\n","                    disc_loss.item(), gen_loss.item(), D_x, D_G_z1, D_G_z2, style_entropy))  \n","\n","        # Save Losses for plotting later\n","        gen_iter_loss.append(gen_loss.item())\n","        disc_iter_loss.append(disc_loss.item())\n","        entropies.append(style_entropy)\n","\n","        # Check how the generator is doing by saving G's output on fixed_noise\n","        #if (iters % 2000 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n","        if (i == len(dataloader)-1):\n","            with torch.no_grad():\n","                fake_img = generator(fixed_noise, fixed_label).detach().cpu()\n","            img_lst.append(vutils.make_grid(fake_img, nrow = example_size,padding=2, normalize=True))\n","\n","        iters += 1\n","    gen_loss_avg[-1] /= num_batches\n","    disc_loss_avg[-1] /= num_batches\n","\n","#arian arian error to solve"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rZA1OzrgG6mo"},"source":["### Load Checkpoints"]},{"cell_type":"code","metadata":{"id":"In-M-HMiG3RN","executionInfo":{"status":"aborted","timestamp":1623858494085,"user_tz":-120,"elapsed":110,"user":{"displayName":"Arian Askari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiIw8AJ_FyYd3Z5pNgWvAnfn3agwPoJEASc1wWK3w=s64","userId":"06715765459286968049"}}},"source":["# load models\n","disc_save_name = 'wikiart_dc_gen.cpt'\n","gen_save_name = 'wikiart_dc_disc.cpt'\n","\n","path_gen = F'/content/drive/MyDrive/neural_networks/checkpoints/{gen_save_name}'\n","path_disc = F'/content/drive/MyDrive/neural_networks/checkpoints/{disc_save_name}'\n","\n","# check whether checkpoint files exist\n","if os.path.isfile(path_gen) and os.path.isfile(path_disc) == True:\n","    checkpoint_gen = torch.load(path_gen)\n","    checkpoint_disc = torch.load(path_disc)\n","\n","    # neural net is saved on the gpu we send it to the cpu via .to(device)\n","    generator = Generator().to(device)\n","    discriminator = Discriminator().to(device)\n","    # given the kernel shut done and all variables are lost\n","    # optimizers need to be initialised again\n","    gen_optimizer = torch.optim.Adam(params=generator.parameters(), \n","                                     lr=learning_rate, betas=(0.5, 0.999))\n","    disc_optimizer = torch.optim.Adam(params=discriminator.parameters(), \n","                                      lr=learning_rate, betas=(0.5, 0.999))\n","    generator.load_state_dict(checkpoint_gen['gen_state_dict'])\n","    discriminator.load_state_dict(checkpoint_disc['disc_state_dict'])\n","    gen_optimizer.load_state_dict(checkpoint_gen['optimizer_state_dict'])\n","    disc_optimizer.load_state_dict(checkpoint_disc['optimizer_state_dict'])\n","    epoch = checkpoint_gen['epoch']\n","    img_lst = checkpoint_gen['img_lst']\n","    img_lst_gif = checkpoint_gen['img_lst_gif']\n","    gen_loss_avg = checkpoint_gen['gen_loss_avg']\n","    disc_loss_avg = checkpoint_disc['disc_loss_avg']\n","else: \n","    print(\"Checkpoint files not found or do not exist.\")\n","    print(\"The neural network may have not been trained yet.\")\n","#model_gen.eval()\n","# - or -\n","#model_gen.train()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6DjtzZkF-0uI"},"source":["### Figures: First and Last Image"]},{"cell_type":"code","metadata":{"id":"kn9xbL07-hyp","executionInfo":{"status":"aborted","timestamp":1623858494087,"user_tz":-120,"elapsed":111,"user":{"displayName":"Arian Askari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiIw8AJ_FyYd3Z5pNgWvAnfn3agwPoJEASc1wWK3w=s64","userId":"06715765459286968049"}}},"source":["# plot 1st image\n","plt.figure(figsize=(20,20))\n","plt.subplot(1,2,1)\n","plt.axis(\"off\")\n","plt.title(\"First Image\")\n","plt.imshow(np.transpose(vutils.make_grid(img_lst[0].to(device), padding=2, normalize=True).cpu(),(1,2,0)))\n","# plot last image\n","plt.subplot(1,2,2)\n","plt.axis(\"off\")\n","plt.title(\"Last Image\")\n","plt.imshow(np.transpose(vutils.make_grid(img_lst[-1].to(device), padding=2, normalize=True).cpu(),(1,2,0)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ErFNzP2Pn8Bu"},"source":["### Plot: Real Images vs Generated Images"]},{"cell_type":"code","metadata":{"id":"H9t4RYFUe-oc","executionInfo":{"status":"aborted","timestamp":1623858494091,"user_tz":-120,"elapsed":113,"user":{"displayName":"Arian Askari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiIw8AJ_FyYd3Z5pNgWvAnfn3agwPoJEASc1wWK3w=s64","userId":"06715765459286968049"}}},"source":["# Real vs Fake\n","# Grab a batch of real images from the dataloader\n","real_batch = next(iter(dataloader))\n","\n","# Plot the real images\n","plt.figure(figsize=(15,15))\n","plt.subplot(1,2,1)\n","plt.axis(\"off\")\n","plt.title(\"Real Images\")\n","plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n","\n","# Plot the fake images from the last epoch\n","plt.subplot(1,2,2)\n","plt.axis(\"off\")\n","plt.title(\"Fake Images\")\n","plt.imshow(np.transpose(img_lst[-1],(1,2,0)))\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j7q8QhO9n5zb","executionInfo":{"status":"aborted","timestamp":1623858494095,"user_tz":-120,"elapsed":115,"user":{"displayName":"Arian Askari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiIw8AJ_FyYd3Z5pNgWvAnfn3agwPoJEASc1wWK3w=s64","userId":"06715765459286968049"}}},"source":["# Grab a batch of real images from the dataloader\n","# Plot the real images\n","plt.figure(figsize=(15,15))\n","plt.subplot(1,2,1)\n","plt.axis(\"off\")\n","plt.title(\"Real Images\")\n","plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, \n","                                         normalize=True).cpu(),(1,2,0)))\n","\n","# Plot the fake images from the last epoch\n","plt.subplot(1,2,2)\n","plt.axis(\"off\")\n","plt.title(\"Generated Images\")\n","plt.imshow(np.transpose(img_lst_gif[-1].cpu().numpy(),(1,2,0)))\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r-0yLIej_EF-"},"source":["### Gif: Image Generation Process"]},{"cell_type":"code","metadata":{"id":"Ub1_x4ix_B2n","executionInfo":{"status":"aborted","timestamp":1623858494097,"user_tz":-120,"elapsed":116,"user":{"displayName":"Arian Askari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiIw8AJ_FyYd3Z5pNgWvAnfn3agwPoJEASc1wWK3w=s64","userId":"06715765459286968049"}}},"source":["# gif from starting image to last generated image\n","#%%capture\n","# if bytes for gif are too big increase limit \n","plt.rcParams['animation.embed_limit'] = 2**128\n","fig = plt.figure(figsize=(8,8))\n","plt.axis(\"off\")\n","ims = [[plt.imshow(np.transpose(i.cpu().numpy(),(1,2,0)), animated=True)] for i in img_lst_gif]\n","ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n","HTML(ani.to_jshtml())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dJisNfHe_61i"},"source":["### Training Curves"]},{"cell_type":"code","metadata":{"id":"9tlVu7hk_-if","executionInfo":{"status":"aborted","timestamp":1623858494103,"user_tz":-120,"elapsed":121,"user":{"displayName":"Arian Askari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiIw8AJ_FyYd3Z5pNgWvAnfn3agwPoJEASc1wWK3w=s64","userId":"06715765459286968049"}}},"source":["# Plot average loss per epoch\n","plt.figure(figsize=(13,5))\n","plt.subplot(1,2,1)\n","#plt.plot(gen_loss_avg, linewidth=1.5)\n","#plt.plot(disc_loss_avg, linewidth=1.5)\n","#plt.title('Average loss per epoch', fontsize = 16)\n","#plt.xlabel('Number of epochs', fontsize = 16)\n","#plt.ylabel('Mean Loss', fontsize = 16)\n","#plt.legend(['Generator', 'Discriminator'], \n","#           prop={'size': 14},           \n","#            frameon=False)\n","\n","# Plot loss per iteration\n","plt.subplot(1,2,2)\n","plt.plot(gen_iter_loss, linewidth=1.5)\n","plt.plot(disc_iter_loss, linewidth=1.5)\n","plt.title('Loss per iteration', fontsize = 16)\n","plt.xlabel('Number of iterations', fontsize = 16)\n","plt.ylabel('Loss', fontsize = 16)\n","plt.legend(['Generator', 'Discriminator'], \n","           prop={'size': 14},           \n","            frameon=False)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9AULvMqTjWQB"},"source":["### Image Evaluation Metrics"]},{"cell_type":"markdown","metadata":{"id":"oGXiqq27gnbY"},"source":["Inception score"]},{"cell_type":"code","metadata":{"id":"KCRB4-I4jfUk","executionInfo":{"status":"aborted","timestamp":1623858494106,"user_tz":-120,"elapsed":124,"user":{"displayName":"Arian Askari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiIw8AJ_FyYd3Z5pNgWvAnfn3agwPoJEASc1wWK3w=s64","userId":"06715765459286968049"}}},"source":["stedv, means = [], []\n","imgs = []\n","for j in range(len(img_lst)):\n","  for i in range(len(img_lst[j])):\n","    imgs.append((vutils.make_grid(img_lst[j][i].to(device), padding=2, normalize=True).cpu()))\n","  if (j % 20 == 0): \n","    print('Image metric computed for [%d / %d]' % (j, len(img_lst)))\n","  mean, stdv = inception_score(imgs, cuda=True, batch_size=32, resize=True, splits=10)\n","  means.append(mean)\n","  stedv.append(stdv)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YVwggq20gp5W"},"source":["Frechet Inception Distance"]},{"cell_type":"code","metadata":{"id":"5cU3U_yGg0Rz","executionInfo":{"status":"aborted","timestamp":1623858494107,"user_tz":-120,"elapsed":121,"user":{"displayName":"Arian Askari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiIw8AJ_FyYd3Z5pNgWvAnfn3agwPoJEASc1wWK3w=s64","userId":"06715765459286968049"}}},"source":["real_batch = next(iter(dataloader))\n","fids = []\n","for i in range(len(img_lst)):\n","  fids.append(frechet_id(img_lst[i], real_batch))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"50jqcH7SxrRD","executionInfo":{"status":"aborted","timestamp":1623858494109,"user_tz":-120,"elapsed":122,"user":{"displayName":"Arian Askari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiIw8AJ_FyYd3Z5pNgWvAnfn3agwPoJEASc1wWK3w=s64","userId":"06715765459286968049"}}},"source":["# Plot average loss per epoch\n","plt.figure(figsize=(13,5))\n","plt.subplot(1,2,1)\n","plt.plot(means, linewidth=1.5)\n","plt.title('Inception score per epoch', fontsize = 16)\n","plt.xlabel('Number of epochs', fontsize = 16)\n","plt.ylabel('Inception score', fontsize = 16)\n","plt.legend(['IS'], \n","           prop={'size': 14},           \n","            frameon=False)\n","\n","# Plot loss per iteration\n","plt.subplot(1,2,2)\n","plt.plot(fids, linewidth=1.5)\n","plt.title('Frechet inception distance per epoch', fontsize = 16)\n","plt.xlabel('Number of epochs', fontsize = 16)\n","plt.ylabel('Frechet inception distance', fontsize = 16)\n","plt.legend(['FID'], \n","           prop={'size': 14},           \n","            frameon=False)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"biK8PNqFxxSN"},"source":["NEvAr Metric"]},{"cell_type":"code","metadata":{"id":"wPFGjEBRx0Mv","executionInfo":{"status":"aborted","timestamp":1623858494110,"user_tz":-120,"elapsed":122,"user":{"displayName":"Arian Askari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiIw8AJ_FyYd3Z5pNgWvAnfn3agwPoJEASc1wWK3w=s64","userId":"06715765459286968049"}}},"source":["\n","import tensorflow as tf\n","# convert pytorch tensor to np array\n","tensor_to_np = img_lst[110].detach().cpu().numpy()\n","# convert np array to tf tensor\n","tf_tensor = tf.convert_to_tensor(tensor_to_np)\n","# set it as image\n","img = tf_tensor\n","# perform tf sobel edge operation\n","grad_components = tf.image.sobel_edges(img)\n","# compute gradient magnitute \n","grad_mag_components = grad_components**2\n","# sum magnitude components\n","grad_mag_square = tf.math.reduce_sum(grad_mag_components,axis=-1)\n","# sobel edge detected image\n","grad_mag_img = tf.sqrt(grad_mag_square)\n","# convert tf tensor to np array\n","tensor_img = grad_mag_img.numpy()\n","# plot sobel operaiton on image for testing\n","#plt.imshow(tensor_img[0][0])\n","\n","# convert numpy image to pytorch tensor\n","tensor_img = torch.from_numpy(tensor_img)\n","# plot using pytorch\n","\n","# plot original image\n","plt.figure(figsize=(12,12))\n","plt.subplot(1,2,1)\n","plt.axis(\"off\")\n","plt.title(\"Original Image\")\n","plt.imshow(np.transpose(vutils.make_grid(img_lst[110][0].to(device), padding=2, \n","                                         normalize=True).cpu(),(1,2,0)))\n","plt.subplot(1,2,2)\n","plt.axis(\"off\")\n","plt.title(\"Sobel Operation\")\n","plt.imshow(np.transpose(vutils.make_grid(tensor_img[0][0].to(device), padding=2, \n","                                         normalize=True).cpu(),(1,2,0)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bl83QE1_yF26","executionInfo":{"status":"aborted","timestamp":1623858494112,"user_tz":-120,"elapsed":124,"user":{"displayName":"Arian Askari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiIw8AJ_FyYd3Z5pNgWvAnfn3agwPoJEASc1wWK3w=s64","userId":"06715765459286968049"}}},"source":["def grayscale(image):\n","    grey = np.mean(image, axis = 0)\n","    return grey\n","from scipy import ndimage\n","# image = img_lst[110][0] # single tensor image isolate from batch \n","image = img_lst[110][0].detach().cpu().numpy()\n","image = grayscale(image)\n","print(image.shape)\n","#image = grayscale(image)\n","#image = img_lst[110][0].detach().cpu().numpy()\n","img_x = ndimage.sobel(image, 0) # sobel operation across horizontal\n","img_y = ndimage.sobel(image, 1) # sobel operation across vertical\n","sob = np.hypot(img_x, img_y)\n","# sob = grayscale(sob)\n","#sob = np.sum(sob, axis = [-1,-1,-1])\n","#grad_comp = np.sqrt(img_x + img_y)\n","#grad_comp = np.sum(grad_comp,axis=-1)\n","#grad_mag_sqrt = np.sum(grad_comp, axis = -1)\n","#grad_mag_imge = np.sqrt(grad_mag_sqrt)\n","#tf.math.reduce_sum(grad_comp,axis=-1)\n","#image_sobel = np.sqrt((img_x ** 2) + (img_y **2))\n","# transpose image to obtain correct dimensions\n","# plot\n","# plt.imshow(np.transpose(grad_mag_imge,(1,2,0)))\n","#plt.imshow(np.transpose(grad_comp,(1,2,0)))\n","plt.imshow(sob, cmap='gray')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IFduMAhMyPFm","executionInfo":{"status":"aborted","timestamp":1623858494114,"user_tz":-120,"elapsed":125,"user":{"displayName":"Arian Askari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiIw8AJ_FyYd3Z5pNgWvAnfn3agwPoJEASc1wWK3w=s64","userId":"06715765459286968049"}}},"source":["from scipy import ndimage\n","image = img_lst[110][0] # single tensor image isolate from batch \n","#image = grayscale(image)\n","print(image.shape)\n","#image = grayscale(image)\n","#image = img_lst[110][0].detach().cpu().numpy()\n","img_x = ndimage.sobel(image, 0) # sobel operation across horizontal\n","img_y = ndimage.sobel(image, 1) # sobel operation across vertical\n","sob = np.hypot(img_x, img_y)\n","sob = grayscale(sob)\n","# sob = np.sum(sob, axis = [-1,-1,-1])\n","# grad_comp = np.sqrt(img_x + img_y)\n","# grad_comp = np.sum(grad_comp,axis=-1)\n","# grad_mag_sqrt = np.sum(grad_comp, axis = -1)\n","# grad_mag_imge = np.sqrt(grad_mag_sqrt)\n","# tf.math.reduce_sum(grad_comp,axis=-1)\n","# image_sobel = np.sqrt((img_x ** 2) + (img_y **2))\n","# transpose image to obtain correct dimensions\n","# plot\n","# plt.imshow(np.transpose(grad_mag_imge,(1,2,0)))\n","# plt.imshow(np.transpose(grad_comp,(1,2,0)))\n","plt.imshow(sob, cmap='gray')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dJNobgeeVu35"},"source":["### Save singles of generated images"]},{"cell_type":"code","metadata":{"id":"MJv39DkyV_cy","executionInfo":{"status":"aborted","timestamp":1623858494118,"user_tz":-120,"elapsed":128,"user":{"displayName":"Arian Askari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiIw8AJ_FyYd3Z5pNgWvAnfn3agwPoJEASc1wWK3w=s64","userId":"06715765459286968049"}}},"source":["# stores a single image\n","#for j in range(len(img_lst)):\n","#  for i in range(len(img_lst[j])):\n","#    torchvision.utils.save_image(img_lst[j][i], '/content/drive/MyDrive/neural_networks/wikiart_gen_imgs/%d%d.JPG' % (j,i), normalize = True)\n","    #imgs.append((vutils.make_grid(img_lst[j][i].to(device), padding=2, normalize=True).cpu()))\n","#  if (j % 20 == 0): \n","#    print('Stores [%d / %d] image batches' % (j * len(img_lst[0]) , len(img_lst[0])* len(img_lst)))"],"execution_count":null,"outputs":[]}]}